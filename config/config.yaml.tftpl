# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

google_cloud_project:
  project_id: "${project_id}"
  project_name: "${project_name}"
  project_number: "${project_number}"
  region: "${cloud_region}"

cloud_build:
  project_id: "${project_id}"
  region: "${cloud_region}"
  github:
    owner: "${pipelines_github_owner}"
    repo_name: "${pipelines_github_repo}"
    trigger_branch: "dev"
  build_file: "cloudbuild/pipelines.yaml"
  _REPOSITORY_GCP_PROJECT: "${project_id}"
  _REPOSITORY_NAME: "github_${pipelines_github_owner}_${pipelines_github_repo}"
  _REPOSITORY_BRANCH: "main"
  _GCR_HOSTNAME: "${cloud_region}-docker.pkg.dev"
  _BUILD_REGION: "${cloud_region}"

container:
  builder:
    base:
      from_image: "python:3.7-alpine3.7"
      base_image_name: "base-builder"
      base_image_prefix: "propensity-modeling"
    zetasql:
      from_image: "wbsouza/zetasql-formatter:latest"
      base_image_name: "zetasql-formatter"
      base_image_prefix: "propensity-modeling"
  container_registry_hostname: "${cloud_region}-docker.pkg.dev"
  container_registry_region: "${cloud_region}"

artifact_registry:
  pipelines_repo:
    name: "pipelines-repo"
    region: "${cloud_region}"
    project_id: "${project_id}"
  pipelines_docker_repo:
    name: "pipelines-docker-repo"
    region: "${cloud_region}"
    project_id: "${project_id}"

dataflow:
  worker_service_account_id: "df-worker"
  worker_service_account: "df-worker@${project_id}.iam.gserviceaccount.com"

vertex_ai:
  components:
    base_image_name: "ma-components"
    base_image_tag: "dev"

  pipelines: 
    project_id: "${project_id}"
    service_account_id: "vertex-pipelines-sa"
    service_account: "vertex-pipelines-sa@${project_id}.iam.gserviceaccount.com"
    region: "${cloud_region}"
    bucket_name: "${project_id}-pipelines"
    root_path: "gs://${project_id}-pipelines/pipelines/"

    feature-creation-auto-audience-segmentation:
      execution:
        name: "feature-creation-auto-audience-segmentation"
        job_id_prefix: "feature-creation-auto-audience-segmentation-"
        experiment_name: "feature-creation-auto-audience-segmentation"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 1 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          dataset: "auto_audience_segmentation"
          feature_table: "page_path_cumulative_traffic"
          mds_project_id: "${mds_project_id}"
          mds_dataset: "${mds_dataset}"
          date_start: "2023-01-01"
          date_end: "2023-12-31"
          stored_procedure_name: "auto_audience_segmentation_training_preparation"
          training_table: "auto_audience_segmentation_training_full_dataset"
          reg_expression: '^https://shop.googlemerchandisestore.com/([-a-zA-Z0-9@:%_+.~#?//=]*)$'
          perc_keep: 35
          lookback_days: 15
          query_auto_audience_segmentation_inference_preparation: "
            CALL `{auto_audience_segmentation_inference_preparation_procedure_name}`();"
          query_parameters:
            - { name: "input_date", type: "DATE", value: None } # If value is not defined then assume current_date()
          timeout: 3600.0
        pipeline_parameters_substitutions: # Substitutions are applied to the parameters before compilation
          date_timezone: "UTC" # used when input_date is None and need to get current date.
          auto_audience_segmentation_inference_preparation_procedure_name: "${project_id}.auto_audience_segmentation.invoke_auto_audience_segmentation_inference_preparation"
          auto_audience_segmentation_training_preparation_procedure_name: "${project_id}.auto_audience_segmentation.invoke_auto_audience_segmentation_training_preparation"
    

    feature-creation-audience-segmentation:
      execution:
        name: "feature-creation-audience-segmentation"
        job_id_prefix: "feature-creation-audience-segmentation-"
        experiment_name: "feature-creation-audience-segmentation"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 1 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          query_user_segmentation_dimensions: "
            CALL `{user_segmentation_dimensions_procedure_name}`();"
          query_user_lookback_metrics: "
            CALL `{user_lookback_metrics_procedure_name}`();"
          query_user_scoped_segmentation_metrics: "
            CALL `{user_scoped_segmentation_metrics_procedure_name}`();"
          
          query_audience_segmentation_inference_preparation: "
            CALL `{audience_segmentation_inference_preparation_procedure_name}`();"

          query_audience_segmentation_training_preparation: "
            CALL `{audience_segmentation_training_preparation_procedure_name}`();"
          
          query_parameters:
            - { name: "input_date", type: "DATE", value: None } # If value is not defined then assume current_date()
          timeout: 3600.0
        pipeline_parameters_substitutions: # Substitutions are applied to the parameters before compilation
          user_segmentation_dimensions_procedure_name: "${project_id}.feature_store.invoke_user_segmentation_dimensions"
          user_lookback_metrics_procedure_name: "${project_id}.feature_store.invoke_user_lookback_metrics"
          user_scoped_segmentation_metrics_procedure_name: "${project_id}.feature_store.invoke_user_scoped_segmentation_metrics"
          date_timezone: "UTC" # used when input_date is None and need to get current date.

          audience_segmentation_inference_preparation_procedure_name: "${project_id}.audience_segmentation.invoke_audience_segmentation_inference_preparation"

          audience_segmentation_training_preparation_procedure_name: "${project_id}.audience_segmentation.invoke_audience_segmentation_training_preparation"

    
    feature-creation-purchase-propensity: 
      execution:
        name: "feature-creation-purchase-propensity"
        job_id_prefix: "feature-creation-purchase-propensity-"
        experiment_name: "feature-creation-purchase-propensity"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 1 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          query_purchase_propensity_label: "
            CALL `{purchase_propensity_label_procedure_name}`();"
          query_user_dimensions: "
            CALL `{user_dimensions_procedure_name}`();"
          query_user_rolling_window_metrics: "
            CALL `{user_rolling_window_metrics_procedure_name}`();"
          query_user_scoped_metrics: "
            CALL `{user_scoped_metrics_procedure_name}`();"
          query_user_session_event_aggregated_metrics: "
            CALL `{user_session_event_aggregated_metrics_procedure_name}`();"
          
          query_purchase_propensity_inference_preparation: "
            CALL `{purchase_propensity_inference_preparation_procedure_name}`();"

          query_purchase_propensity_training_preparation: "
            CALL `{purchase_propensity_training_preparation_procedure_name}`();"
          
          query_parameters:
            - { name: "input_date", type: "DATE", value: None } # If value is not defined then assume current_date()
          timeout: 3600.0
        pipeline_parameters_substitutions: # Substitutions are applied to the parameters before compilation
          purchase_propensity_label_procedure_name: "${project_id}.feature_store.invoke_purchase_propensity_label"
          user_dimensions_procedure_name: "${project_id}.feature_store.invoke_user_dimensions"
          user_rolling_window_metrics_procedure_name: "${project_id}.feature_store.invoke_user_rolling_window_metrics"
          user_scoped_metrics_procedure_name: "${project_id}.feature_store.invoke_user_scoped_metrics"
          user_session_event_aggregated_metrics_procedure_name: "${project_id}.feature_store.invoke_user_session_event_aggregated_metrics"
          date_timezone: "UTC" # used when input_date is None and need to get current date.

          purchase_propensity_inference_preparation_procedure_name: "${project_id}.purchase_propensity.invoke_purchase_propensity_inference_preparation"
          
          purchase_propensity_training_preparation_procedure_name: "${project_id}.purchase_propensity.invoke_purchase_propensity_training_preparation"

    feature-creation-customer-ltv:
      execution:
        name: "feature-creation-customer-ltv"
        job_id_prefix: "feature-creation-customer-ltv-"
        experiment_name: "feature-creation-customer-ltv"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 1 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          query_customer_lifetime_value_label: "
            CALL `{customer_lifetime_value_label_procedure_name}`();"
          query_user_lifetime_dimensions: "
            CALL `{user_lifetime_dimensions_procedure_name}`();"
          query_user_rolling_window_lifetime_metrics: "
            CALL `{user_rolling_window_lifetime_metrics_procedure_name}`();"
          query_user_scoped_lifetime_metrics: "
            CALL `{user_scoped_lifetime_metrics_procedure_name}`();"
          
          query_customer_lifetime_value_inference_preparation: "
            CALL `{customer_lifetime_value_inference_preparation_procedure_name}`();"
          
          query_customer_lifetime_value_training_preparation: "
            CALL `{customer_lifetime_value_training_preparation_procedure_name}`();"
          
          query_parameters:
            - { name: "input_date", type: "DATE", value: None } # If value is not defined then assume current_date()
          timeout: 3600.0
        pipeline_parameters_substitutions: # Substitutions are applied to the parameters before compilation
          customer_lifetime_value_label_procedure_name: "${project_id}.feature_store.invoke_customer_lifetime_value_label"
          user_lifetime_dimensions_procedure_name: "${project_id}.feature_store.invoke_user_lifetime_dimensions"
          user_rolling_window_lifetime_metrics_procedure_name: "${project_id}.feature_store.invoke_user_rolling_window_lifetime_metrics"
          user_scoped_lifetime_metrics_procedure_name: "${project_id}.feature_store.invoke_user_scoped_lifetime_metrics"
          date_timezone: "UTC" # used when input_date is None and need to get current date.

          customer_lifetime_value_inference_preparation_procedure_name: "${project_id}.customer_lifetime_value.invoke_customer_lifetime_value_inference_preparation"
          
          customer_lifetime_value_training_preparation_procedure_name: "${project_id}.customer_lifetime_value.invoke_customer_lifetime_value_training_preparation"
          

    propensity:
      training:
        name: "propensity-training-pl"
        job_id_prefix: "propensity-training-pl-"
        experiment_name: "propensity-training"
        type: "tabular-workflows"
        schedule:
          cron: "TZ=America/New_York 0 8 * * SAT"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project: "${project_id}"
          location: "${cloud_region}"
          root_dir: "gs://${project_id}-pipelines/propensity-training"
          transformations: "gs://${project_id}-pipelines/propensity-training/transformations_config_{timestamp}.json"
          custom_transformations: "pipelines/transformations-purchase-propensity.json"
          train_budget_milli_node_hours: 1000 # 1 hour
          max_selected_features: 20
          apply_feature_selection_tuning: true
          run_evaluation: true
          run_distillation: false
          prediction_type: "classification"
          optimization_objective: "minimize-log-loss"
          target_column: "will_purchase"
          predefined_split_key: "data_split"
          data_source_csv_filenames: null
          training_fraction: null
          validation_fraction: null
          test_fraction: null
          # data_source_bigquery_table_path: "bq://${project_id}.purchase_propensity.v_purchase_propensity_training_15_7"
          # data_source_bigquery_table_path: "bq://${project_id}.purchase_propensity.v_purchase_propensity_training_15_15"
          data_source_bigquery_table_path: "bq://${project_id}.purchase_propensity.v_purchase_propensity_training_30_15_balanced"
          data_source_bigquery_table_schema: "../sql/schema/table/purchase_propensity_training_preparation.json"
          dataflow_service_account: "df-worker@${project_id}.iam.gserviceaccount.com"
          timestamp_split_key: null
          stratified_split_key: null
          weight_column: null
          additional_experiments: null
          export_additional_model_without_custom_ops: false
          #study_spec_parameters_override:
          #  - parameter_id: "model_type"
          #    categorical_value_spec:
          #      values: 
          #        - nn
          #        - boosted_trees
          #  - parameter_id: "feature_selection_rate"
          #    double_value_spec:
          #      min_value: 0.5
          #      max_value: 1.0
          #    scale_type: UNIT_LINEAR_SCALE
        exclude_features:
          - processed_timestamp
          - data_split
          - feature_date
          - user_pseudo_id
          - user_id
          - will_purchase
        pipeline_parameters_substitutions: null 
      prediction:
        name: "propensity-prediction-pl"
        job_id_prefix: "propensity-prediction-pl-"
        experiment_name: "propensity-prediction"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 5 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${cloud_region}"
          job_name_prefix: "propensity-prediction-pl-"
          model_display_name: "propensity-training-pl-model" # must match the model name defined in the training pipeline. for now it is {NAME_OF_PIPELINE}-model
          model_metric_name: "logLoss"
          model_metric_threshold: 0.9
          number_of_models_considered: 1
          bigquery_source: "${project_id}.purchase_propensity.v_purchase_propensity_inference_30_15"
          bigquery_destination_prefix: "${project_id}.purchase_propensity"
          bq_unique_key: "user_pseudo_id"
          machine_type: "n1-standard-4"
          max_replica_count: 10
          batch_size: 64
          accelerator_count: 0
          accelerator_type: "ACCELERATOR_TYPE_UNSPECIFIED" # ONE OF ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100, NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4
          generate_explanation: false
          threashold: 0.5
          positive_label: "1"
          aggregated_predictions_dataset_location: "${location}"
          query_aggregate_last_day_predictions: "CALL `${project_id}.aggregated_predictions.aggregate_last_day_predictions`();"
          pubsub_activation_topic: "activation-trigger"
          pubsub_activation_type: "purchase-propensity-30-15"  # purchase-propensity-30-15 | purchase-propensity-15-15 | purchase-propensity-15-7" 
        pipeline_parameters_substitutions: null
    
    segmentation:
      training:
        name: "segmentation-training-pl"
        job_id_prefix: "segmentation-training-pl-"
        experiment_name: "segmentation-training"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 12 * * SAT"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          km_num_clusters: 14
          km_init_method: "KMEANS++"
          km_distance_type: "EUCLIDEAN"
          km_standardize_features: "TRUE"
          km_max_interations: 20
          km_early_stop: "TRUE"
          km_min_rel_progress: 0.01
          km_warm_start: "FALSE"
          model_dataset_id: "${project_id}.audience_segmentation" # to also include project.dataset
          model_name_bq_prefix: "audience_segmentation_model" # must match the model name defined in the training pipeline. for now it is {NAME_OF_PIPELINE}-model
          vertex_model_name: "audience_segmentation_model"
          training_data_bq_table: "${project_id}.audience_segmentation.v_audience_segmentation_training_15"
          exclude_features:
            - processed_timestamp
            - data_split
            - feature_date
            - user_pseudo_id
            - user_id
        pipeline_parameters_substitutions: null
      prediction:
        name: "segmentation-prediction-pl"
        job_id_prefix: "segmentation-prediction-pl-"
        experiment_name: "segmentation-prediction"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 7 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${location}"
          model_dataset_id: "${project_id}.audience_segmentation" # to also include project.dataset
          model_name_bq_prefix: "audience_segmentation_model" # must match the model name defined in the training pipeline. for now it is {NAME_OF_PIPELINE}-model
          model_metric_name: "davies_bouldin_index" # one of davies_bouldin_index ,  mean_squared_distance
          model_metric_threshold: 10 
          number_of_models_considered: 2
          bigquery_source: "${project_id}.audience_segmentation.v_audience_segmentation_inference_15"
          bigquery_destination_prefix: "${project_id}.audience_segmentation.pred_audience_segmentation_inference_15"
          aggregated_predictions_dataset_location: "${location}"
          query_aggregate_last_day_predictions: "CALL `${project_id}.aggregated_predictions.aggregate_last_day_predictions`();"
          pubsub_activation_topic: "activation-trigger"
          pubsub_activation_type: "audience-segmentation-15" # audience-segmentation-15
        pipeline_parameters_substitutions: null

    auto_segmentation:
      training:
        name: "auto-segmentation-training-pl"
        job_id_prefix: "auto-segmentation-training-pl-"
        experiment_name: "auto-segmentation-training"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 12 * * SAT"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          location: "${location}"
          project_id: "${project_id}"
          dataset: "auto_audience_segmentation"
          model_name: "interest-cluster-model"
          training_table: "auto_audience_segmentation_training_full_dataset"
          p_wiggle: 10
          min_num_clusters: 3
          bucket_name: "${project_id}-custom-models"
          image_uri: "us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest"
        pipeline_parameters_substitutions: null
      prediction:
        name: "auto-segmentation-prediction-pl"
        job_id_prefix: "auto-segmentation-prediction-pl-"
        experiment_name: "auto-segmentation-prediction"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 2 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${cloud_region}"
          model_name: "interest-cluster-model"
          bigquery_source: "${project_id}.auto_audience_segmentation.v_auto_audience_segmentation_inference_15"
          bigquery_destination_prefix: "${project_id}.auto_audience_segmentation.p_auto_audience_segmentation_inference_15"
          pubsub_activation_topic: "activation-trigger"
          pubsub_activation_type: "auto-audience-segmentation-15"
        pipeline_parameters_substitutions: null

    ## CLV training and inference pipeline requires a purchase propensity model training and a ltv regression model training. 
    ## Finally, a unique prediction pipeline.
    propensity_clv:
      training:
        name: "propensity-clv-training-pl"
        job_id_prefix: "propensity-clv-training-pl-"
        experiment_name: "propensity-clv-training"
        type: "tabular-workflows"
        schedule:
          cron: "TZ=America/New_York 0 16 * * SAT"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project: "${project_id}"
          location: "${cloud_region}"
          root_dir: "gs://${project_id}-pipelines/propensity-clv-training"
          transformations: "gs://${project_id}-pipelines/propensity-clv-training/transformations_config_{timestamp}.json"
          train_budget_milli_node_hours: 1000 # 1 hour
          max_selected_features: 20
          apply_feature_selection_tuning: true
          run_evaluation: true
          run_distillation: false
          prediction_type: "classification"
          optimization_objective: "minimize-log-loss"
          target_column: "will_purchase"
          predefined_split_key: "data_split"
          data_source_csv_filenames: null
          training_fraction: null
          validation_fraction: null
          test_fraction: null
          data_source_bigquery_table_path: "bq://${project_id}.purchase_propensity.v_purchase_propensity_training_30_30_balanced"
          data_source_bigquery_table_schema: "../sql/schema/table/purchase_propensity_training_preparation.json"
          dataflow_service_account: "df-worker@${project_id}.iam.gserviceaccount.com"
          timestamp_split_key: null
          stratified_split_key: null
          weight_column: null
          additional_experiments: null
          export_additional_model_without_custom_ops: false
          #study_spec_parameters_override:
          #  - parameter_id: "model_type"
          #    categorical_value_spec:
          #      values: 
          #        - nn
          #        - boosted_trees
          #  - parameter_id: "feature_selection_rate"
          #    double_value_spec:
          #      min_value: 0.5
          #      max_value: 1.0
          #    scale_type: UNIT_LINEAR_SCALE
        exclude_features:
          - processed_timestamp
          - data_split
          - feature_date
          - user_pseudo_id
          - user_id
          - will_purchase
        pipeline_parameters_substitutions: null 
    clv:
      training:
        name: "clv-training-pl"
        job_id_prefix: "clv-training-pl-"
        experiment_name: "clv-training"
        type: "tabular-workflows"
        schedule:
          cron: "TZ=America/New_York 0 20 * * SAT"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project: "${project_id}"
          location: "${cloud_region}"
          root_dir: "gs://${project_id}-pipelines/clv-training"
          transformations: "gs://${project_id}-pipelines/clv-training/transformations_config_{timestamp}.json"
          custom_transformations: "pipelines/transformations-customer-ltv.json"
          train_budget_milli_node_hours: 1000 # 1 hour
          max_selected_features: 20 
          apply_feature_selection_tuning: true
          run_evaluation: true
          run_distillation: false
          prediction_type: "regression"
          target_column: "pltv_revenue_30_days"
          predefined_split_key: "data_split"
          training_fraction: null
          validation_fraction: null
          test_fraction: null
          data_source_csv_filenames: null
          optimization_objective: minimize-mae # minimize-mae | minimize-rmse | minimize-rmsle
          data_source_bigquery_table_path: "bq://${project_id}.customer_lifetime_value.v_customer_lifetime_value_training_180_30"
          data_source_bigquery_table_schema: "../sql/schema/table/customer_lifetime_value_training_preparation.json"
          dataflow_service_account: "df-worker@${project_id}.iam.gserviceaccount.com"
          timestamp_split_key: null
          stratified_split_key: null
          weight_column: null
          additional_experiments: null
          export_additional_model_without_custom_ops: false
          #study_spec_parameters_override:
          #  - parameter_id: "model_type"
          #    categorical_value_spec:
          #      values: 
          #        - nn
          #        - boosted_trees
          #  - parameter_id: "feature_selection_rate"
          #    double_value_spec:
          #      min_value: 0.5
          #      max_value: 1.0
          #    scale_type: UNIT_LINEAR_SCALE
        exclude_features:
          - processed_timestamp
          - data_split
          - feature_date
          - user_pseudo_id
          - user_id
        pipeline_parameters_substitutions: null 
      prediction:
        name: "clv-prediction-pl"
        job_id_prefix: "clv-prediction-pl-"
        experiment_name: "clv-prediction"
        type: "custom"
        schedule:
          cron: "TZ=America/New_York 0 6 * * *"
          max_concurrent_run_count: 1
          start_time: null
          end_time: null
          state: ACTIVE # possible states ACTIVE or PAUSED
        pipeline_parameters:
          project_id: "${project_id}"
          location: "${cloud_region}"
          purchase_job_name_prefix: "propensity-prediction-pl-"
          clv_job_name_prefix: "clv-prediction-pl-"
          purchase_model_display_name: "propensity-clv-training-pl-model" # must match the model name defined in the training pipeline. for now it is {NAME_OF_PIPELINE}-model
          purchase_model_metric_name: "logLoss"
          purchase_model_metric_threshold: 0.9
          number_of_purchase_models_considered: 1
          generate_explanation: false
          threashold: 0.5
          positive_label: "1"
          clv_model_display_name: "clv-training-pl-model" # must match the model name defined in the training pipeline. for now it is {NAME_OF_PIPELINE}-model
          clv_model_metric_name: "meanAbsoluteError" #'rootMeanSquaredError', 'meanAbsoluteError', 'meanAbsolutePercentageError', 'rSquared', 'rootMeanSquaredLogError'
          clv_model_metric_threshold: 400
          number_of_clv_models_considered: 1
          purchase_bigquery_source: "${project_id}.purchase_propensity.v_purchase_propensity_inference_30_30"
          purchase_bigquery_destination_prefix: "${project_id}.customer_lifetime_value"
          clv_bigquery_source: "${project_id}.customer_lifetime_value.v_customer_lifetime_value_inference_180_30"
          clv_bigquery_destination_prefix: "${project_id}.customer_lifetime_value"
          purchase_bq_unique_key: "user_pseudo_id"
          clv_bq_unique_key: "user_pseudo_id"
          machine_type: "n1-standard-4"
          max_replica_count: 10
          batch_size: 64
          accelerator_count: 0
          accelerator_type: "ACCELERATOR_TYPE_UNSPECIFIED" # ONE OF ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100, NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4
          generate_explanation: false
          aggregated_predictions_dataset_location: "${location}"
          query_aggregate_last_day_predictions: "CALL `${project_id}.aggregated_predictions.aggregate_last_day_predictions`();"
          pubsub_activation_topic: "activation-trigger"
          pubsub_activation_type: "cltv-180-30" # cltv-180-180 | cltv-180-90 | cltv-180-30
        pipeline_parameters_substitutions: null

bigquery:
  project_id: "${project_id}"
  region: "${location}"
  dataset:
    feature_store:
      project_id: "${project_id}"
      name: "feature_store"
      location: "${location}"
      collation: "und:ci"
      is_case_insensitive: TRUE
      description: "Feature Store dataset for Marketing behavioural modeling"
      friendly_name: "Feature Store"
      max_time_travel_hours: 168 
      default_partition_expiration_days: 365
      default_table_expiration_days: 365
    purchase_propensity:
      name: "purchase_propensity"
      location: "${location}"
      project_id: "${project_id}"
      collation: "und:ci"
      is_case_insensitive: TRUE
      description: "Purchase Propensity Use Case dataset for Marketing behavioural modeling"
      friendly_name: "Purchase Propensity Dataset"
      max_time_travel_hours: 168
      default_partition_expiration_days: 365
      default_table_expiration_days: 365
    customer_lifetime_value:
      project_id: "${project_id}"
      name: "customer_lifetime_value"
      location: "${location}"
      collation: "und:ci"
      is_case_insensitive: TRUE
      description: "Customer Lifetime Value Use Case dataset for Marketing behavioural modeling"
      friendly_name: "Customer Lifetime Value Dataset"
      max_time_travel_hours: 168
      default_partition_expiration_days: 365
      default_table_expiration_days: 365
    audience_segmentation:
      project_id: "${project_id}"
      name: "audience_segmentation"
      location: "${location}"
      collation: "und:ci"
      is_case_insensitive: TRUE
      description: "Audience Segmentation Use Case dataset for Marketing behavioural modeling"
      friendly_name: "Audience Segmentation Dataset"
      max_time_travel_hours: 168
      default_partition_expiration_days: 365
      default_table_expiration_days: 365
    auto_audience_segmentation:
      project_id: "${project_id}"
      name: "auto_audience_segmentation"
      location: "${location}"
      collation: "und:ci"
      is_case_insensitive: TRUE
      description: "Auto Audience Segmentation Use Case dataset for Marketing behavioural modeling"
      friendly_name: "Auto Audience Segmentation Dataset"
      max_time_travel_hours: 48
      default_partition_expiration_days: 365
      default_table_expiration_days: 365
    aggregated_predictions:
      project_id: "${project_id}"
      name: "aggregated_predictions"
      location: "${location}"
      description: "Dataset with aggregated prediction results from multiple use cases"
      friendly_name: "Aggregated Predictions Dataset"
  table:
    audience_segmentation_inference_preparation:
      project_id: "${project_id}"
      dataset: "audience_segmentation"
      table_name: "audience_segmentation_inference_preparation"
      location: "${location}"
      table_description: "Audience Segmentation Inference Preparation table to be used for Model Prediction"
    customer_lifetime_value_inference_preparation:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      table_name: "customer_lifetime_value_inference_preparation"
      location: "${location}"
      table_description: "Customer Lifetime Value Inference Preparation table to be used for Model Prediction"
    customer_lifetime_value_label:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      table_name: "customer_lifetime_value_label"
      location: "${location}"
      table_description: "Customer Lifetime Value Inference Preparation table to be used for Model Prediction"
    purchase_propensity_inference_preparation:
      project_id: "${project_id}"
      dataset: "purchase_propensity"
      table_name: "purchase_propensity_inference_preparation"
      location: "${location}"
      table_description: "Purchase Propensity Inference Preparation table to be used for Model Prediction"
    purchase_propensity_label:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "purchase_propensity_label"
      location: "${location}"
      table_description: "Purchase Propensity Label table to be used for Model Prediction"
    user_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_dimensions"
      location: "${location}"
      table_description: "User Dimensions table as part of the Feature Store"
    user_lifetime_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_lifetime_dimensions"
      location: "${location}"
      table_description: "User Lifetime Dimensions table as part of the Feature Store"
    user_lookback_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_lookback_metrics"
      location: "${location}"
      table_description: "User Lookback Metrics table as part of the Feature Store"
    user_rolling_window_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_rolling_window_lifetime_metrics"
      location: "${location}"
      table_description: "User Rolling Window Lifetime Metrics table as part of the Feature Store" 
    user_rolling_window_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_rolling_window_metrics"
      location: "${location}"
      table_description: "User Rolling Window Metrics table as part of the Feature Store"
    user_scoped_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_scoped_lifetime_metrics"
      location: "${location}"
      table_description: "User Scoped Lifetime Metrics table as part of the Feature Store"
    user_scoped_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_scoped_metrics"
      location: "${location}"
      table_description: "User Scoped Metrics table as part of the Feature Store"
    user_scoped_segmentation_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_scoped_segmentation_metrics"
      location: "${location}"
      table_description: "User Scoped Segmentation Metrics table as part of the Feature Store" 
    user_segmentation_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_segmentation_dimensions"
      location: "${location}"
      table_description: "User Segmentation Dimensions table as part of the Feature Store"
    user_session_event_aggregated_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      table_name: "user_session_event_aggregated_metrics"
      location: "${location}"
      table_description: "User Session Event Aggregated Metrics table as part of the Feature Store" 
  query:
    audience_segmentation_query_template:
      none: none
    auto_audience_segmentation_query_template:
      none: none
    purchase_propensity_query_template:
      none: none
    cltv_query_template:
      none: none
    invoke_purchase_propensity_training_preparation:
      project_id: "${project_id}"
      dataset: "purchase_propensity"
      stored_procedure: "purchase_propensity_training_preparation"
      interval_max_date: 15
      interval_min_date: 30
      train_start_date: "2022-01-01"
      train_end_date: "2023-03-12"
      train_split_end_number: 5
      validation_split_end_number: 8
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    invoke_audience_segmentation_training_preparation:
      project_id: "${project_id}"
      dataset: "audience_segmentation"
      stored_procedure: "audience_segmentation_training_preparation"
      interval_max_date: 1
      interval_min_date: 15
      train_start_date: "2022-01-01"
      train_end_date: "2023-03-12"
      train_split_end_number: 5
      validation_split_end_number: 8
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    invoke_customer_lifetime_value_training_preparation:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      stored_procedure: "customer_lifetime_value_training_preparation"
      interval_max_date: 180
      interval_min_date: 180
      train_start_date: "2022-01-01"
      train_end_date: "2023-03-12"
      train_split_end_number: 5
      validation_split_end_number: 8
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}" 
    invoke_backfill_user_lifetime_dimensions:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_lifetime_dimensions"
      interval_max_date: 180
      interval_min_date: 180
      interval_end_date: 180
    invoke_backfill_user_scoped_lifetime_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}" 
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_scoped_lifetime_metrics"
      interval_max_date: 180
      interval_min_date: 180
      interval_end_date: 180
    invoke_backfill_user_session_event_aggregated_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}" 
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_session_event_aggregated_metrics"
      interval_max_date: 15
      interval_min_date: 30
      interval_end_date: 30
    invoke_backfill_customer_lifetime_value_label:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "customer_lifetime_value_label"
      interval_max_date: 180
      interval_min_date: 180
      interval_end_date: 180
    invoke_backfill_user_lookback_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_lookback_metrics"
      interval_min_date: 15
      interval_end_date: 15
    invoke_backfill_user_rolling_window_lifetime_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_rolling_window_lifetime_metrics"
      interval_max_date: 180
      interval_min_date: 180
      interval_end_date: 180
    invoke_backfill_user_scoped_segmentation_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_scoped_segmentation_metrics"
      interval_min_date: 15
      interval_end_date: 15 
    invoke_backfill_user_segmentation_dimensions:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_segmentation_dimensions"
      interval_min_date: 15
      interval_end_date: 15
    invoke_backfill_purchase_propensity_label:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "purchase_propensity_label"
      interval_max_date: 15
      interval_min_date: 30
      interval_end_date: 30
    invoke_backfill_user_dimensions:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_dimensions"
      interval_max_date: 15
      interval_min_date: 30
      interval_end_date: 30
    invoke_backfill_user_rolling_window_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}" 
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_rolling_window_metrics"
      interval_max_date: 15
      interval_min_date: 30
      interval_end_date: 30
    invoke_backfill_user_scoped_metrics:
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      project_id: "${project_id}"
      dataset: "feature_store"
      insert_table: "user_scoped_metrics"
      interval_max_date: 15
      interval_min_date: 30
      interval_end_date: 30 
    invoke_customer_lifetime_value_label:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "customer_lifetime_value_label"
      interval_input_date: 180
    invoke_purchase_propensity_label:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "purchase_propensity_label"
      interval_input_date: 15
    invoke_user_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_dimensions"
      interval_end_date: 180
    invoke_user_lifetime_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_lifetime_dimensions"
      interval_end_date: 180 
    invoke_user_scoped_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_scoped_lifetime_metrics"
      interval_end_date: 180 
    invoke_user_session_event_aggregated_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_session_event_aggregated_metrics"
      interval_end_date: 180
    invoke_user_lookback_metrics: 
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_lookback_metrics"
      interval_end_date: 180
    invoke_user_rolling_window_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_rolling_window_lifetime_metrics"
      interval_end_date: 180
    invoke_user_scoped_segmentation_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_scoped_segmentation_metrics"
      interval_end_date: 180
    invoke_user_segmentation_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_segmentation_dimensions"
      interval_end_date: 180
    invoke_user_rolling_window_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_rolling_window_metrics"
      interval_end_date: 180
    invoke_user_scoped_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      stored_procedure: "user_scoped_metrics"
      interval_end_date: 180 
    invoke_purchase_propensity_inference_preparation:
      project_id: "${project_id}"
      dataset: "purchase_propensity"
      stored_procedure: "purchase_propensity_inference_preparation"
    invoke_customer_lifetime_value_inference_preparation:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      stored_procedure: "customer_lifetime_value_inference_preparation"
    invoke_audience_segmentation_inference_preparation:
      project_id: "${project_id}"
      dataset: "audience_segmentation"
      stored_procedure: "audience_segmentation_inference_preparation"
    invoke_auto_audience_segmentation_inference_preparation:
      project_id: "${project_id}"
      dataset: "auto_audience_segmentation"
      stored_procedure: "auto_audience_segmentation_inference_preparation"
  procedure:
    audience_segmentation_training_preparation:
      project_id: "${project_id}"
      dataset: "audience_segmentation"
      name: "audience_segmentation_training_preparation"
      insert_table: "audience_segmentation_training_full_dataset"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      expiration_duration_hours: 168
      samples_per_split: 100000
    customer_lifetime_value_label:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "customer_lifetime_value_label"
      insert_table: "customer_lifetime_value_label"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    customer_lifetime_value_training_preparation:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      name: "customer_lifetime_value_training_preparation"
      insert_table: "customer_lifetime_value_training_full_dataset"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      expiration_duration_hours: 168
    purchase_propensity_label:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "purchase_propensity_label"
      insert_table: "purchase_propensity_label"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    purchase_propensity_training_preparation:
      project_id: "${project_id}"
      dataset: "purchase_propensity"
      name: "purchase_propensity_training_preparation"
      insert_table: "purchase_propensity_training_full_dataset"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
      expiration_duration_hours: 168
    user_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_dimensions"
      insert_table: "user_dimensions"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_lifetime_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_lifetime_dimensions"
      insert_table: "user_lifetime_dimensions"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_lookback_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_lookback_metrics"
      insert_table: "user_lookback_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_rolling_window_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_rolling_window_lifetime_metrics"
      insert_table: "user_rolling_window_lifetime_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_rolling_window_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_rolling_window_metrics"
      insert_table: "user_rolling_window_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_scoped_lifetime_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_scoped_lifetime_metrics"
      insert_table: "user_scoped_lifetime_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_scoped_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_scoped_metrics"
      insert_table: "user_scoped_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_scoped_segmentation_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_scoped_segmentation_metrics"
      insert_table: "user_scoped_segmentation_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_segmentation_dimensions:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_segmentation_dimensions"
      insert_table: "user_segmentation_dimensions"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    user_session_event_aggregated_metrics:
      project_id: "${project_id}"
      dataset: "feature_store"
      name: "user_session_event_aggregated_metrics"
      insert_table: "user_session_event_aggregated_metrics"
      mds_project_id: "${mds_project_id}"
      mds_dataset: "${mds_dataset}"
    purchase_propensity_inference_preparation:
      project_id: "${project_id}"
      dataset: "purchase_propensity"
      name: "purchase_propensity_inference_preparation"
      feature_store_project_id: "${project_id}" 
      feature_store_dataset: "feature_store"
      insert_table: "purchase_propensity_inference_preparation"
      expiration_duration_hours: 168
    customer_lifetime_value_inference_preparation:
      project_id: "${project_id}"
      dataset: "customer_lifetime_value"
      name: "customer_lifetime_value_inference_preparation"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      insert_table: "customer_lifetime_value_inference_preparation"
      expiration_duration_hours: 168
    audience_segmentation_inference_preparation:
      project_id: "${project_id}"
      dataset: "audience_segmentation"
      name: "audience_segmentation_inference_preparation"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      insert_table: "audience_segmentation_inference_preparation"
      expiration_duration_hours: 168
      mds_dataset: "${mds_dataset}"
    auto_audience_segmentation_inference_preparation:
      project_id: "${project_id}"
      dataset: "auto_audience_segmentation"
      name: "auto_audience_segmentation_inference_preparation"
      feature_store_project_id: "${project_id}"
      feature_store_dataset: "feature_store"
      insert_table: "auto_audience_segmentation_inference_preparation"
      expiration_duration_hours: 12
      mds_dataset: "${mds_dataset}"
    aggregate_predictions_procedure:
      project_id: "${project_id}"
      dataset_id: "aggregated_predictions"
      table_id: "latest"
      customer_lifetime_value_dataset: "customer_lifetime_value"
      purchase_propensity_dataset: "purchase_propensity"
      audience_segmentation_dataset: "audience_segmentation"

  
